"""
BERT (Multilingual) ê°œì¸ì •ë³´ ë¬¸ë§¥ ì´í•´ í…ŒìŠ¤íŠ¸
"""

import torch
import time
import sys
from transformers import BertTokenizer, BertModel
import numpy as np

class BERTPrivacyTester:
    def __init__(self):
        self.model = None
        self.tokenizer = None

    def test_installation(self):
        """BERT ì„¤ì¹˜ í™•ì¸"""
        try:
            from transformers import BertTokenizer, BertModel
            print("âœ… BERT (transformers) ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ!")
            return True
        except ImportError as e:
            print(f"âŒ BERT import ì‹¤íŒ¨: {e}")
            return False

    def load_model(self):
        """BERT ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë”©"""
        try:
            print("ğŸ”„ BERT Multilingual ëª¨ë¸ ë¡œë”© ì¤‘...")
            start_time = time.time()

            # ë‹¤êµ­ì–´ BERT ëª¨ë¸ ì‚¬ìš© (í•œêµ­ì–´ ì§€ì›)
            model_name = 'bert-base-multilingual-cased'
            self.tokenizer = BertTokenizer.from_pretrained(model_name)
            self.model = BertModel.from_pretrained(model_name)
            self.model.eval()

            load_time = time.time() - start_time
            print(f"âœ… BERT ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {load_time:.2f}ì´ˆ)")
            print(f"ğŸ“Š ëª¨ë¸ ì •ë³´: {model_name}")

            return True
        except Exception as e:
            print(f"âŒ BERT ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False

    def test_tokenization(self):
        """í† í¬ë‚˜ì´ì§• í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”¤ BERT í† í¬ë‚˜ì´ì§• í…ŒìŠ¤íŠ¸")
        print("-" * 50)

        test_sentences = [
            "ì•ˆë…•í•˜ì„¸ìš” ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤",
            "ì „í™”ë²ˆí˜¸ëŠ” 010-1234-5678ì…ë‹ˆë‹¤",
            "35ì„¸ ë‚¨ì„± ì˜ì‚¬ì´ê³  ê°•ë‚¨êµ¬ì— ê±°ì£¼í•©ë‹ˆë‹¤",
            "API key is sk-abc123",
            "Patient Kim Cheol-su had surgery yesterday"
        ]

        for sentence in test_sentences:
            tokens = self.tokenizer.tokenize(sentence)
            token_ids = self.tokenizer.encode(sentence)

            print(f"ì›ë¬¸: {sentence}")
            print(f"í† í°: {tokens[:10]}{'...' if len(tokens) > 10 else ''}")
            print(f"í† í° ìˆ˜: {len(tokens)}, ID ìˆ˜: {len(token_ids)}")
            print()

    def get_sentence_embedding(self, text):
        """ë¬¸ì¥ ì„ë² ë”© ì¶”ì¶œ"""
        try:
            # í† í¬ë‚˜ì´ì§• ë° ì¸ì½”ë”©
            encoding = self.tokenizer(
                text,
                add_special_tokens=True,
                max_length=128,
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            )

            with torch.no_grad():
                outputs = self.model(**encoding)
                # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš© (pooler_output ë˜ëŠ” last_hidden_state[:, 0])
                sentence_embedding = outputs.pooler_output.squeeze()

            return sentence_embedding

        except Exception as e:
            print(f"ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def test_similarity(self):
        """ë¬¸ë§¥ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” BERT ë¬¸ë§¥ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸")
        print("-" * 50)

        test_pairs = [
            ("í™˜ì ê¹€ì² ìˆ˜ê°€ ìˆ˜ìˆ ë°›ì•˜ìŠµë‹ˆë‹¤", "ê¹€ì² ìˆ˜ êµìˆ˜ë‹˜ì´ ê°•ì˜í•˜ì…¨ìŠµë‹ˆë‹¤", "í™˜ì vs êµìˆ˜"),
            ("Patient Kim had surgery", "Doctor Kim gave a lecture", "ì˜ì–´: í™˜ì vs ì˜ì‚¬"),
            ("35ì„¸ ë‚¨ì„± ì˜ì‚¬", "40ëŒ€ ì—¬ì„± ê°„í˜¸ì‚¬", "ì˜ë£Œì§„ ì •ë³´"),
            ("API key sk-abc123", "password password123", "ì¸ì¦ ì •ë³´"),
            ("í˜ˆë‹¹ 350 ì¼€í†¤ì‚°ì¦", "blood sugar 350 ketoacidosis", "í•œêµ­ì–´ vs ì˜ì–´")
        ]

        for text1, text2, desc in test_pairs:
            try:
                emb1 = self.get_sentence_embedding(text1)
                emb2 = self.get_sentence_embedding(text2)

                if emb1 is not None and emb2 is not None:
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                    similarity = torch.cosine_similarity(emb1, emb2, dim=0).item()

                    print(f"ğŸ“Š {desc}")
                    print(f"  í…ìŠ¤íŠ¸1: {text1}")
                    print(f"  í…ìŠ¤íŠ¸2: {text2}")
                    print(f"  ìœ ì‚¬ë„: {similarity:.4f}")

                    if similarity > 0.8:
                        print("  ğŸ”´ ë§¤ìš° ìœ ì‚¬")
                    elif similarity > 0.6:
                        print("  ğŸŸ¡ ì–´ëŠì •ë„ ìœ ì‚¬")
                    elif similarity > 0.4:
                        print("  ğŸŸ¢ ì•½ê°„ ìœ ì‚¬")
                    else:
                        print("  ğŸ”µ ë‚®ì€ ìœ ì‚¬ë„")
                    print()

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {e}")
                print()

    def test_multilingual_support(self):
        """ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸"""
        print("\nğŸŒ BERT ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸")
        print("-" * 50)

        multilingual_tests = [
            ("ê¹€ì² ìˆ˜ëŠ” ì˜ì‚¬ì…ë‹ˆë‹¤", "Korean"),
            ("Kim Cheol-su is a doctor", "English"),
            ("é‡‘å“²ç§€æ˜¯åŒ»ç”Ÿ", "Chinese"),
            ("ã‚­ãƒ ãƒ»ãƒãƒ§ãƒ«ã‚¹ã¯åŒ»è€…ã§ã™", "Japanese")
        ]

        embeddings = []
        for text, lang in multilingual_tests:
            try:
                embedding = self.get_sentence_embedding(text)
                if embedding is not None:
                    embeddings.append((text, lang, embedding))
                    print(f"âœ… {lang}: {text}")
                    print(f"   ì„ë² ë”© ì°¨ì›: {embedding.shape}")
                else:
                    print(f"âŒ {lang}: ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ {lang}: {e}")

        # ì–¸ì–´ê°„ ìœ ì‚¬ë„ ë¹„êµ
        print("\nğŸ”— ì–¸ì–´ê°„ ì˜ë¯¸ ìœ ì‚¬ë„:")
        if len(embeddings) >= 2:
            korean_emb = embeddings[0][2]  # í•œêµ­ì–´
            for i in range(1, len(embeddings)):
                other_emb = embeddings[i][2]
                similarity = torch.cosine_similarity(korean_emb, other_emb, dim=0).item()
                print(f"  í•œêµ­ì–´ vs {embeddings[i][1]}: {similarity:.4f}")
        print()

    def test_privacy_detection(self):
        """ê°œì¸ì •ë³´ ê°ì§€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ›¡ï¸ BERT ê°œì¸ì •ë³´ ê°ì§€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("-" * 50)

        test_cases = [
            ("ì•ˆë…•í•˜ì„¸ìš” ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤", "ì§ì ‘ ê°œì¸ì •ë³´", "HIGH"),
            ("My name is John Smith and my email is john@example.com", "ì˜ì–´ ê°œì¸ì •ë³´", "HIGH"),
            ("ì „í™”ë²ˆí˜¸ëŠ” 010-1234-5678ì…ë‹ˆë‹¤", "ì „í™”ë²ˆí˜¸", "HIGH"),
            ("35ì„¸ ë‚¨ì„± ì˜ì‚¬ì´ê³  ê°•ë‚¨êµ¬ì— ê±°ì£¼í•©ë‹ˆë‹¤", "ì¡°í•© ì •ë³´", "MEDIUM"),
            ("í™˜ì ê¹€ì² ìˆ˜ê°€ ì–´ì œ ìˆ˜ìˆ ë°›ì•˜ìŠµë‹ˆë‹¤", "ì˜ë£Œ ë§¥ë½", "HIGH"),
            ("ê¹€ì² ìˆ˜ êµìˆ˜ë‹˜ì´ ê°•ì˜í•˜ì…¨ìŠµë‹ˆë‹¤", "êµìœ¡ ë§¥ë½", "LOW"),
            ("API key is sk-abc123def456", "ê¸°ìˆ  ì •ë³´", "HIGH"),
            ("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”", "ì¼ë°˜ í…ìŠ¤íŠ¸", "NONE"),
            ("The weather is nice today", "ì˜ì–´ ì¼ë°˜ í…ìŠ¤íŠ¸", "NONE")
        ]

        for text, category, expected_risk in test_cases:
            try:
                embedding = self.get_sentence_embedding(text)

                if embedding is not None:
                    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ìœ„í—˜ë„ ê³„ì‚°
                    privacy_score = 0.0

                    # í•œêµ­ì–´ í‚¤ì›Œë“œ
                    if any(keyword in text for keyword in ['ì´ë¦„', 'ê¹€ì² ìˆ˜', 'ë°•ì˜í¬']):
                        privacy_score += 0.3
                    if any(keyword in text for keyword in ['010-', 'ì „í™”ë²ˆí˜¸']):
                        privacy_score += 0.4
                    if any(keyword in text for keyword in ['ì˜ì‚¬', 'í™˜ì', 'ìˆ˜ìˆ ']):
                        privacy_score += 0.2

                    # ì˜ì–´ í‚¤ì›Œë“œ
                    if any(keyword in text.lower() for keyword in ['name', 'email', 'phone']):
                        privacy_score += 0.3
                    if any(keyword in text for keyword in ['john', 'smith', '@']):
                        privacy_score += 0.3
                    if any(keyword in text.lower() for keyword in ['doctor', 'patient', 'surgery']):
                        privacy_score += 0.2

                    # ê³µí†µ ê¸°ìˆ  í‚¤ì›Œë“œ
                    if any(keyword in text.lower() for keyword in ['api', 'sk-', 'password', 'key']):
                        privacy_score += 0.4
                    if any(keyword in text for keyword in ['ì„¸', 'ê°•ë‚¨êµ¬', 'ê±°ì£¼']):
                        privacy_score += 0.1

                    print(f"ğŸ“ {category}")
                    print(f"  í…ìŠ¤íŠ¸: {text}")
                    print(f"  ì˜ˆìƒ ìœ„í—˜ë„: {expected_risk}")
                    print(f"  ê³„ì‚°ëœ ì ìˆ˜: {privacy_score:.2f}")
                    print(f"  ì„ë² ë”© ì°¨ì›: {embedding.shape}")
                    print()

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {e}")
                print()

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª BERT (Multilingual) ê°œì¸ì •ë³´ ê°ì§€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    tester = BERTPrivacyTester()

    # 1. ì„¤ì¹˜ í™•ì¸
    if not tester.test_installation():
        print("âŒ BERT ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    # 2. ëª¨ë¸ ë¡œë”©
    if not tester.load_model():
        print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        sys.exit(1)

    # 3. í† í¬ë‚˜ì´ì§• í…ŒìŠ¤íŠ¸
    tester.test_tokenization()

    # 4. ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸
    tester.test_multilingual_support()

    # 5. ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
    tester.test_similarity()

    # 6. ê°œì¸ì •ë³´ ê°ì§€ í…ŒìŠ¤íŠ¸
    tester.test_privacy_detection()

    print("\n" + "=" * 60)
    print("ğŸ“‹ BERT í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print("âœ… í™•ì¸ëœ ê¸°ëŠ¥:")
    print("  - ë‹¤êµ­ì–´ í† í¬ë‚˜ì´ì§• (í•œêµ­ì–´, ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´)")
    print("  - ë¬¸ì¥ ì„ë² ë”© ìƒì„± (768ì°¨ì›)")
    print("  - ì–¸ì–´ê°„ ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚°")
    print("  - ê¸°ë³¸ì ì¸ ë¬¸ë§¥ ì´í•´")
    print()
    print("âš ï¸ í•œê³„ì :")
    print("  - í•œêµ­ì–´ íŠ¹í™” ì„±ëŠ¥ KoBERT ëŒ€ë¹„ ë¶€ì¡±")
    print("  - ê°œì¸ì •ë³´ íŠ¹í™” fine-tuning í•„ìš”")
    print("  - ì¡°í•© ìœ„í—˜ë„ íŒë‹¨ ì•Œê³ ë¦¬ì¦˜ ë³„ë„ í•„ìš”")
    print()
    print("ğŸ¯ ê²°ë¡ : BERTëŠ” ë‹¤êµ­ì–´ ì§€ì›ì´ ê°•ì ì´ì§€ë§Œ,")
    print("       í•œêµ­ì–´ ê°œì¸ì •ë³´ ê°ì§€ì—ëŠ” KoBERTê°€ ë” ì í•©í•  ìˆ˜ ìˆìŒ")

if __name__ == "__main__":
    main()
