"""
LLM ì„¤ì • íŒŒì¼ - 2025ë…„ 7ì›” ìµœì‹  ëª¨ë¸
ë‹¤ì–‘í•œ LLM ì œê³µìì˜ ìµœì‹  ëª¨ë¸ ì„¤ì •ì„ ê´€ë¦¬
"""

import os
import logging
from typing import Dict, List
from dataclasses import dataclass
from enum import Enum
from dotenv import load_dotenv

load_dotenv()

class RiskLevel(Enum):
    """ìœ„í—˜ë„ ë ˆë²¨ ì •ì˜"""
    NONE = 0
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class LLMConfig:
    """LLM ì„¤ì • í´ë˜ìŠ¤"""
    name: str
    provider: str
    model_id: str
    api_key: str
    temperature: float = 0.1
    max_tokens: int = 1000
    cost_per_1k_tokens: float = 0.003
    available: bool = True
    description: str = ""

class LLMConfigManager:
    """LLM ì„¤ì • ê´€ë¦¬ì"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.configs = self._setup_all_configs()

    def _setup_all_configs(self) -> Dict[str, LLMConfig]:
        """ëª¨ë“  LLM ì„¤ì • ì´ˆê¸°í™”"""
        configs = {}

        # OpenAI ëª¨ë¸ë“¤ ì¶”ê°€
        configs.update(self._setup_openai_configs())

        # Anthropic ëª¨ë¸ë“¤ ì¶”ê°€
        configs.update(self._setup_anthropic_configs())

        # Google ëª¨ë¸ë“¤ ì¶”ê°€
        configs.update(self._setup_google_configs())

        # Cohere ëª¨ë¸ë“¤ ì¶”ê°€
        configs.update(self._setup_cohere_configs())

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ í•„í„°ë§
        available_configs = {k: v for k, v in configs.items() if v.available}

        self.logger.info(f"ì´ {len(available_configs)}ê°œ LLM ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
        return available_configs

    def _setup_openai_configs(self) -> Dict[str, LLMConfig]:
        """OpenAI ëª¨ë¸ ì„¤ì •"""
        configs = {}

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            self.logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return configs

        try:
            import openai

            configs.update({
                'gpt-4.1': LLMConfig(
                    name='GPT-4.1',
                    provider='openai',
                    model_id='gpt-4.1',
                    api_key=api_key,
                    cost_per_1k_tokens=0.006,
                    max_tokens=2000,
                    description='ìµœì‹  OpenAI ëª¨ë¸, 100ë§Œ í† í° ë¬¸ë§¥ ì²˜ë¦¬'
                ),
                'gpt-4o': LLMConfig(
                    name='GPT-4o',
                    provider='openai',
                    model_id='gpt-4o',
                    api_key=api_key,
                    cost_per_1k_tokens=0.005,
                    description='ê°•ë ¥í•œ ë²”ìš© ëª¨ë¸'
                ),
                'gpt-4o-mini': LLMConfig(
                    name='GPT-4o-Mini',
                    provider='openai',
                    model_id='gpt-4o-mini',
                    api_key=api_key,
                    cost_per_1k_tokens=0.00015,
                    description='ë¹ ë¥´ê³  ì €ë ´í•œ ê²½ëŸ‰ ëª¨ë¸'
                )
            })

            self.logger.info(f"OpenAI ëª¨ë¸ {len(configs)}ê°œ ì„¤ì • ì™„ë£Œ")

        except ImportError:
            self.logger.warning("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return configs

    def _setup_anthropic_configs(self) -> Dict[str, LLMConfig]:
        """Anthropic ëª¨ë¸ ì„¤ì •"""
        configs = {}

        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            self.logger.warning("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return configs

        try:
            import anthropic

            configs.update({
                'claude-opus-4': LLMConfig(
                    name='Claude-Opus-4',
                    provider='anthropic',
                    model_id='claude-opus-4-20250514',
                    api_key=api_key,
                    cost_per_1k_tokens=0.02,
                    max_tokens=2000,
                    description='ìµœê³  ì„±ëŠ¥ Claude ëª¨ë¸, ì½”ë”©Â·ì¶”ë¡  íŠ¹í™”'
                ),
                'claude-sonnet-4': LLMConfig(
                    name='Claude-Sonnet-4',
                    provider='anthropic',
                    model_id='claude-sonnet-4-20250514',
                    api_key=api_key,
                    cost_per_1k_tokens=0.004,
                    description='ê· í˜•ì¡íŒ ì„±ëŠ¥ì˜ Claude ëª¨ë¸'
                ),
                'claude-3-5-sonnet': LLMConfig(
                    name='Claude-3.5-Sonnet',
                    provider='anthropic',
                    model_id='claude-3-5-sonnet-20241022',
                    api_key=api_key,
                    cost_per_1k_tokens=0.003,
                    description='ì´ì „ ì„¸ëŒ€ ê³ ì„±ëŠ¥ ëª¨ë¸'
                )
            })

            self.logger.info(f"Anthropic ëª¨ë¸ {len(configs)}ê°œ ì„¤ì • ì™„ë£Œ")

        except ImportError:
            self.logger.warning("Anthropic ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return configs

    def _setup_google_configs(self) -> Dict[str, LLMConfig]:
        """Google ëª¨ë¸ ì„¤ì •"""
        configs = {}

        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            self.logger.warning("Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return configs

        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)

            configs.update({
                'gemini-2.5-pro': LLMConfig(
                    name='Gemini-2.5-Pro',
                    provider='google',
                    model_id='gemini-2.5-pro',
                    api_key=api_key,
                    cost_per_1k_tokens=0.004,
                    max_tokens=2000,
                    description='ê³ ë‚œë„ ì¶”ë¡  íŠ¹í™” ëª¨ë¸'
                ),
                'gemini-2.5-flash': LLMConfig(
                    name='Gemini-2.5-Flash',
                    provider='google',
                    model_id='gemini-2.5-flash',
                    api_key=api_key,
                    cost_per_1k_tokens=0.0004,
                    description='ê³ ì† ì²˜ë¦¬ íŠ¹í™” ëª¨ë¸'
                ),
                'gemini-2.5-flash-lite': LLMConfig(
                    name='Gemini-2.5-Flash-Lite',
                    provider='google',
                    model_id='gemini-2.5-flash-lite',
                    api_key=api_key,
                    cost_per_1k_tokens=0.0002,
                    description='ê³ ì† ë¶„ë¥˜ íŠ¹í™” ê²½ëŸ‰ ëª¨ë¸'
                )
            })

            self.logger.info(f"Google ëª¨ë¸ {len(configs)}ê°œ ì„¤ì • ì™„ë£Œ")

        except ImportError:
            self.logger.warning("Google GenerativeAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return configs

    def _setup_cohere_configs(self) -> Dict[str, LLMConfig]:
        """Cohere ëª¨ë¸ ì„¤ì •"""
        configs = {}

        api_key = os.getenv('COHERE_API_KEY')
        if not api_key:
            self.logger.warning("Cohere API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return configs

        try:
            import cohere

            configs.update({
                'command-xlarge': LLMConfig(
                    name='Command-XLarge',
                    provider='cohere',
                    model_id='command-xlarge',
                    api_key=api_key,
                    cost_per_1k_tokens=0.003,
                    description='ë¶„ë¥˜ ì‘ì—… íŠ¹í™” ëª¨ë¸'
                ),
                'command-r-plus': LLMConfig(
                    name='Command-R-Plus',
                    provider='cohere',
                    model_id='command-r-plus',
                    api_key=api_key,
                    cost_per_1k_tokens=0.0025,
                    description='ì§€ì‹œ ì§€í–¥ ì„±ëŠ¥ íŠ¹í™” ëª¨ë¸'
                )
            })

            self.logger.info(f"Cohere ëª¨ë¸ {len(configs)}ê°œ ì„¤ì • ì™„ë£Œ")

        except ImportError:
            self.logger.warning("Cohere ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return configs

    def get_available_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return list(self.configs.keys())

    def get_config(self, model_name: str) -> LLMConfig:
        """íŠ¹ì • ëª¨ë¸ì˜ ì„¤ì • ë°˜í™˜"""
        if model_name not in self.configs:
            raise ValueError(f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return self.configs[model_name]

    def get_precision_group(self) -> List[str]:
        """ì •ë°€ ë¹„êµìš© ëª¨ë¸ ê·¸ë£¹"""
        precision_models = ['gpt-4.1', 'claude-opus-4', 'gemini-2.5-pro']
        return [model for model in precision_models if model in self.configs]

    def get_speed_group(self) -> List[str]:
        """ì†ë„ í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ê·¸ë£¹"""
        speed_models = ['gemini-2.5-flash-lite', 'claude-sonnet-4', 'gpt-4o-mini']
        return [model for model in speed_models if model in self.configs]

    def get_cost_efficient_group(self) -> List[str]:
        """ë¹„ìš© íš¨ìœ¨ì  ëª¨ë¸ ê·¸ë£¹"""
        cost_models = ['gpt-4o-mini', 'gemini-2.5-flash-lite', 'command-r-plus']
        return [model for model in cost_models if model in self.configs]

    def print_summary(self):
        """ì„¤ì • ìš”ì•½ ì¶œë ¥"""
        print("ğŸ¤– LLM ëª¨ë¸ ì„¤ì • ìš”ì•½")
        print("=" * 60)

        if not self.configs:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("API í‚¤ë¥¼ ì„¤ì •í•˜ê³  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return

        providers = {}
        for config in self.configs.values():
            if config.provider not in providers:
                providers[config.provider] = []
            providers[config.provider].append(config)

        for provider, models in providers.items():
            print(f"\nğŸ”§ {provider.upper()}:")
            for model in models:
                print(f"   â€¢ {model.name} (${model.cost_per_1k_tokens:.4f}/1Kí† í°)")
                print(f"     {model.description}")

        print(f"\nğŸ“Š ì‹¤í—˜ ê·¸ë£¹:")
        print(f"   ğŸ¯ ì •ë°€ ë¹„êµ: {self.get_precision_group()}")
        print(f"   âš¡ ì†ë„ í…ŒìŠ¤íŠ¸: {self.get_speed_group()}")
        print(f"   ğŸ’° ë¹„ìš© íš¨ìœ¨: {self.get_cost_efficient_group()}")

if __name__ == "__main__":
    # ì„¤ì • í…ŒìŠ¤íŠ¸
    manager = LLMConfigManager()
    manager.print_summary()